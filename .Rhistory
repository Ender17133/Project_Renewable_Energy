n.trees = n.trees)
predmat = predict(boost_boston,
newdata = Boston[-train, ],
n.trees = n.trees)
dim(predmat)
berr = with(data = Boston[-train, ],
apply( (predmat - medv)^2, 2, mean))
plot(n.trees,
berr,
pch = 19,
ylab = 'Mean Squarred Error',
xlab = '# Trees',
main = 'Boosting Test Error')
abline(h = min(test_err), col = "red")
berr
# gradient boosting machines
boost_boston = gbm(medv~.,
data= Boston[train, ],
distribution = 'gaussian',
n.trees = 10000,
shrinkage = 0.001,
interaction.depth = 4)
summary(boost_boston)
n.trees = seq(from = 100,
to = 10000,
by = 100)
predmat = predict(boost_boston,
newdata = Boston[-train, ],
n.trees = n.trees)
dim(predmat)
berr = with(data = Boston[-train, ],
apply( (predmat - medv)^2, 2, mean))
plot(n.trees,
berr,
pch = 19,
ylab = 'Mean Squarred Error',
xlab = '# Trees',
main = 'Boosting Test Error')
abline(h = min(test_err), col = "red")
berr
# gradient boosting machines
boost_boston = gbm(medv~.,
data= Boston[train, ],
distribution = 'gaussian',
n.trees = 10000,
shrinkage = 0.001,
interaction.depth = 1)
summary(boost_boston)
plot(boost_boston, i = 'lstat')
plot(boost_boston, i = 'rm')
n.trees = seq(from = 100,
to = 10000,
by = 100)
predmat = predict(boost_boston,
newdata = Boston[-train, ],
n.trees = n.trees)
dim(predmat)
berr = with(data = Boston[-train, ],
apply( (predmat - medv)^2, 2, mean))
plot(n.trees,
berr,
pch = 19,
ylab = 'Mean Squarred Error',
xlab = '# Trees',
main = 'Boosting Test Error')
abline(h = min(test_err), col = "red")
berr
# gradient boosting machines
boost_boston = gbm(medv~.,
data= Boston[train, ],
distribution = 'gaussian',
n.trees = 10000,
shrinkage = 0.001,
interaction.depth = 2)
summary(boost_boston)
plot(boost_boston, i = 'lstat')
plot(boost_boston, i = 'rm')
n.trees = seq(from = 100,
to = 10000,
by = 100)
predmat = predict(boost_boston,
newdata = Boston[-train, ],
n.trees = n.trees)
dim(predmat)
berr = with(data = Boston[-train, ],
apply( (predmat - medv)^2, 2, mean))
plot(n.trees,
berr,
pch = 19,
ylab = 'Mean Squarred Error',
xlab = '# Trees',
main = 'Boosting Test Error')
abline(h = min(test_err), col = "red")
berr
# gradient boosting machines
boost_boston = gbm(medv~.,
data= Boston[train, ],
distribution = 'gaussian',
n.trees = 10000,
shrinkage = 0.001,
interaction.depth = 3)
summary(boost_boston)
plot(boost_boston, i = 'lstat')
plot(boost_boston, i = 'rm')
n.trees = seq(from = 100,
to = 10000,
by = 100)
predmat = predict(boost_boston,
newdata = Boston[-train, ],
n.trees = n.trees)
dim(predmat)
berr = with(data = Boston[-train, ],
apply( (predmat - medv)^2, 2, mean))
plot(n.trees,
berr,
pch = 19,
ylab = 'Mean Squarred Error',
xlab = '# Trees',
main = 'Boosting Test Error')
abline(h = min(test_err), col = "red")
berr
# gradient boosting machines
boost_boston = gbm(medv~.,
data= Boston[train, ],
distribution = 'gaussian',
n.trees = 10000,
shrinkage = 0.001,
interaction.depth = 4)
summary(boost_boston)
plot(boost_boston, i = 'lstat')
plot(boost_boston, i = 'rm')
n.trees = seq(from = 100,
to = 10000,
by = 100)
predmat = predict(boost_boston,
newdata = Boston[-train, ],
n.trees = n.trees)
dim(predmat)
berr = with(data = Boston[-train, ],
apply( (predmat - medv)^2, 2, mean))
plot(n.trees,
berr,
pch = 19,
ylab = 'Mean Squarred Error',
xlab = '# Trees',
main = 'Boosting Test Error')
abline(h = min(test_err), col = "red")
berr
# gradient boosting machines
boost_boston = gbm(medv~.,
data= Boston[train, ],
distribution = 'gaussian',
n.trees = 10000,
shrinkage = 0.001,
interaction.depth = 5)
summary(boost_boston)
plot(boost_boston, i = 'lstat')
plot(boost_boston, i = 'rm')
n.trees = seq(from = 100,
to = 10000,
by = 100)
predmat = predict(boost_boston,
newdata = Boston[-train, ],
n.trees = n.trees)
dim(predmat)
berr = with(data = Boston[-train, ],
apply( (predmat - medv)^2, 2, mean))
plot(n.trees,
berr,
pch = 19,
ylab = 'Mean Squarred Error',
xlab = '# Trees',
main = 'Boosting Test Error')
abline(h = min(test_err), col = "red")
berr
interaction.depth = 510
plot(boost_boston, i = 'lstat')
plot(boost_boston, i = 'rm')
# gradient boosting machines
boost_boston = gbm(medv~.,
data= Boston[train, ],
distribution = 'gaussian',
n.trees = 10000,
shrinkage = 0.001,
interaction.depth = 10)
summary(boost_boston)
plot(boost_boston, i = 'lstat')
plot(boost_boston, i = 'rm')
n.trees = seq(from = 100,
to = 10000,
by = 100)
predmat = predict(boost_boston,
newdata = Boston[-train, ],
n.trees = n.trees)
dim(predmat)
berr = with(data = Boston[-train, ],
apply( (predmat - medv)^2, 2, mean))
plot(n.trees,
berr,
pch = 19,
ylab = 'Mean Squarred Error',
xlab = '# Trees',
main = 'Boosting Test Error')
abline(h = min(test_err), col = "red")
berr
# gradient boosting machines
boost_boston = gbm(medv~.,
data= Boston[train, ],
distribution = 'gaussian',
n.trees = 10000,
shrinkage = 0.001,
interaction.depth = 4)
summary(boost_boston)
plot(boost_boston, i = 'lstat')
plot(boost_boston, i = 'rm')
n.trees = seq(from = 100,
to = 10000,
by = 100)
predmat = predict(boost_boston,
newdata = Boston[-train, ],
n.trees = n.trees)
dim(predmat)
berr = with(data = Boston[-train, ],
apply( (predmat - medv)^2, 2, mean))
plot(n.trees,
berr,
pch = 19,
ylab = 'Mean Squarred Error',
xlab = '# Trees',
main = 'Boosting Test Error')
abline(h = min(test_err), col = "red")
berr
# cross validation
boosting.cv
# gradient boosting machines
boost_boston = gbm(medv~.,
data= Boston[train, ],
distribution = 'gaussian',
n.trees = 10000,
shrinkage = 0.005,
interaction.depth = 4)
summary(boost_boston)
plot(boost_boston, i = 'lstat')
plot(boost_boston, i = 'rm')
n.trees = seq(from = 100,
to = 10000,
by = 100)
predmat = predict(boost_boston,
newdata = Boston[-train, ],
n.trees = n.trees)
dim(predmat)
berr = with(data = Boston[-train, ],
apply( (predmat - medv)^2, 2, mean))
plot(n.trees,
berr,
pch = 19,
ylab = 'Mean Squarred Error',
xlab = '# Trees',
main = 'Boosting Test Error')
abline(h = min(test_err), col = "red")
berr
# gradient boosting machines
boost_boston = gbm(medv~.,
data= Boston[train, ],
distribution = 'gaussian',
n.trees = 10000,
shrinkage = 0.1,
interaction.depth = 4)
summary(boost_boston)
plot(boost_boston, i = 'lstat')
plot(boost_boston, i = 'rm')
n.trees = seq(from = 100,
to = 10000,
by = 100)
predmat = predict(boost_boston,
newdata = Boston[-train, ],
n.trees = n.trees)
dim(predmat)
berr = with(data = Boston[-train, ],
apply( (predmat - medv)^2, 2, mean))
plot(n.trees,
berr,
pch = 19,
ylab = 'Mean Squarred Error',
xlab = '# Trees',
main = 'Boosting Test Error')
# gradient boosting machines
boost_boston = gbm(medv~.,
data= Boston[train, ],
distribution = 'gaussian',
n.trees = 10000,
shrinkage = 0.01,
interaction.depth = 4)
summary(boost_boston)
plot(boost_boston, i = 'lstat')
plot(boost_boston, i = 'rm')
n.trees = seq(from = 100,
to = 10000,
by = 100)
predmat = predict(boost_boston,
newdata = Boston[-train, ],
n.trees = n.trees)
dim(predmat)
berr = with(data = Boston[-train, ],
apply( (predmat - medv)^2, 2, mean))
plot(n.trees,
berr,
pch = 19,
ylab = 'Mean Squarred Error',
xlab = '# Trees',
main = 'Boosting Test Error')
abline(h = min(test_err), col = "red")
berr
# cross validation
boosting.cv
# gradient boosting machines
boost_boston = gbm(medv~.,
data= Boston[train, ],
distribution = 'gaussian',
n.trees = 10000,
shrinkage = 0.001,
interaction.depth = 4)
summary(boost_boston)
plot(boost_boston, i = 'lstat')
plot(boost_boston, i = 'rm')
n.trees = seq(from = 100,
to = 10000,
by = 100)
predmat = predict(boost_boston,
newdata = Boston[-train, ],
n.trees = n.trees)
dim(predmat)
berr = with(data = Boston[-train, ],
apply( (predmat - medv)^2, 2, mean))
plot(n.trees,
berr,
pch = 19,
ylab = 'Mean Squarred Error',
xlab = '# Trees',
main = 'Boosting Test Error')
abline(h = min(test_err), col = "red")
berr
# cross validation
boosting.cv
# gradient boosting machines
boost_boston = gbm(medv~.,
data= Boston[train, ],
distribution = 'gaussian',
n.trees = 10000,
shrinkage = 0.0001,
interaction.depth = 4)
summary(boost_boston)
plot(boost_boston, i = 'lstat')
plot(boost_boston, i = 'rm')
n.trees = seq(from = 100,
to = 10000,
by = 100)
predmat = predict(boost_boston,
newdata = Boston[-train, ],
n.trees = n.trees)
dim(predmat)
berr = with(data = Boston[-train, ],
apply( (predmat - medv)^2, 2, mean))
plot(n.trees,
berr,
pch = 19,
ylab = 'Mean Squarred Error',
xlab = '# Trees',
main = 'Boosting Test Error')
abline(h = min(test_err), col = "red")
berr
# gradient boosting machines
boost_boston = gbm(medv~.,
data= Boston[train, ],
distribution = 'gaussian',
n.trees = 10000,
shrinkage = 0.005,
interaction.depth = 4)
summary(boost_boston)
plot(boost_boston, i = 'lstat')
plot(boost_boston, i = 'rm')
n.trees = seq(from = 100,
to = 10000,
by = 100)
predmat = predict(boost_boston,
newdata = Boston[-train, ],
n.trees = n.trees)
dim(predmat)
berr = with(data = Boston[-train, ],
apply( (predmat - medv)^2, 2, mean))
plot(n.trees,
berr,
pch = 19,
ylab = 'Mean Squarred Error',
xlab = '# Trees',
main = 'Boosting Test Error')
abline(h = min(test_err), col = "red")
berr
# gradient boosting machines
boost_boston = gbm(medv~.,
data= Boston[train, ],
distribution = 'gaussian',
n.trees = 10000,
shrinkage = 0.009,
interaction.depth = 4)
summary(boost_boston)
plot(boost_boston, i = 'lstat')
plot(boost_boston, i = 'rm')
n.trees = seq(from = 100,
to = 10000,
by = 100)
predmat = predict(boost_boston,
newdata = Boston[-train, ],
n.trees = n.trees)
dim(predmat)
berr = with(data = Boston[-train, ],
apply( (predmat - medv)^2, 2, mean))
plot(n.trees,
berr,
pch = 19,
ylab = 'Mean Squarred Error',
xlab = '# Trees',
main = 'Boosting Test Error')
abline(h = min(test_err), col = "red")
berr
# gradient boosting machines
boost_boston = gbm(medv~.,
data= Boston[train, ],
distribution = 'gaussian',
n.trees = 10000,
shrinkage = 0.002,
interaction.depth = 4)
summary(boost_boston)
plot(boost_boston, i = 'lstat')
plot(boost_boston, i = 'rm')
n.trees = seq(from = 100,
to = 10000,
by = 100)
predmat = predict(boost_boston,
newdata = Boston[-train, ],
n.trees = n.trees)
dim(predmat)
berr = with(data = Boston[-train, ],
apply( (predmat - medv)^2, 2, mean))
plot(n.trees,
berr,
pch = 19,
ylab = 'Mean Squarred Error',
xlab = '# Trees',
main = 'Boosting Test Error')
abline(h = min(test_err), col = "red")
berr
# gradient boosting machines
boost_boston = gbm(medv~.,
data= Boston[train, ],
distribution = 'gaussian',
n.trees = 20000,
shrinkage = 0.002,
interaction.depth = 4)
summary(boost_boston)
plot(boost_boston, i = 'lstat')
plot(boost_boston, i = 'rm')
n.trees = seq(from = 100,
to = 10000,
by = 100)
predmat = predict(boost_boston,
newdata = Boston[-train, ],
n.trees = n.trees)
dim(predmat)
berr = with(data = Boston[-train, ],
apply( (predmat - medv)^2, 2, mean))
plot(n.trees,
berr,
pch = 19,
ylab = 'Mean Squarred Error',
xlab = '# Trees',
main = 'Boosting Test Error')
abline(h = min(test_err), col = "red")
berr
# cross validation
boosting.cv
pnorm(23, 20, 2)
# if the second and third arguments of pnorm() are omitted, the default values
## are u = 0, and st.d = 1
pnorm(1.5)
# calculating percentiles
qnorm(0.1, 70, 13)
# if the second and third arguments of qnorm() are omitted, the default values
## are u = 0 and st.d = 1
qnorm(0,1)
# if the second and third arguments of qnorm() are omitted, the default values
## are u = 0 and st.d = 1
qnorm(0.1)
### Another Example
# mean = 530
# st.d = 205
# 75th percentile
qnorm(0.75, 530, 205)
### Another example
qnorm(0.95)
### Another example
pnorm(2)
1 - pnorm(2)
install.packages("ggsflabel")
setwd("C:/Users/Beibarys Nyussupov/Documents/Books/Portfollio/Projects/DataViz_FinalProject/DataViz_FinalProject")
render("final.Rmd", "md_document")
library(rmarkdown)
render("final.Rmd", "md_document")
install.package("ggsflabel")
install.packages("ggsflabel")
render("final.Rmd", "md_document")
render("final.Rmd", "md_document")
